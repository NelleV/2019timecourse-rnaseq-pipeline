---
title: "[Normalization] A pipeline to analyse time-course gene expression data"
author:
    - name: Nelle Varoquaux
      affiliation: CNRS, University Grenoble Alpes, TIMC-IMAG, Grenoble, France 
    - name: Elizabeth Purdom
      affiliation: Department of Statistics, University of California, Berkeley, Berkeley, CA

abstract: >
    The phenotypic diversity of cells is governed by a complex equilibrium
    between their genetic identity and their environmental interactions:
    Understanding the dynamics of gene expression is a fundamental question of
    biology. However, analysing time-course transcriptomic data raises unique
    challenging statistical and computational questions, requiring the
    development of novel methods and software.  Using as case study
    time-course transcriptomics data from mice exposed to different strains of
    influenza, this workflows provides a step-by-step tutorial of the
    methodology used to analyse time-course data: (1) normalization of the
    micro-array dataset; (2) differential expression analysis using functional
    data analysis; (3) clustering fo time-course data; (4) interpreting
    clusters with GO term and KEGG pathway enrichment analysis.

keywords: >
    time-course gene expression data, clustering, differential expression,
    workflow
vignette: >
    %\VignetteIndexEntry{A worfklow for low-level analyses of scRNA-seq data}
    %\VignetteEngine{knitr::rmarkdown}
output: BiocWorkflowTools::f1000_article

bibliography: bibliography.bib
---

```{r echo=FALSE, results="hide", message=FALSE}
# Loading dependencies
library(devtools)
library(limma)
library(splines)
library(stats)
library(knitr)
library(kableExtra)
library(BiocStyle)
library(biomaRt)

library(ggplot2)
library(NMF)
library(KEGGprofile)
library(viridis)

library(topGO)

library(moanin)

source("utils.R")
```

```{r echo=FALSE, include=FALSE}
knitr::opts_chunk$set(
  cache=TRUE, autodep=TRUE, warning=FALSE, error=FALSE, message=FALSE,
  echo=TRUE,
  duplicate.label="allow"
)
```


# TODO list



## Quality control and normalization

The first steps of analysis of gene expression data is always to do normalization and quality control checks of the data. In what follows, we show an example of this for the influenza data using generic methods; these steps are not in specific to time course, but could be done for any gene expression analysis. 

### Pre-processing and normalization

**EAP: Should we make this part of the pipeline, or just start with normalization? It's very microarray heavy... We could have a vignette in `moanin` documenting the creation of a normalized version of the data.**

The micro-array data were obtained from NCBI Gene Expression Omnibus (GEO),
with accession number GSE63786. The dataset has a total of 209 samples, with
45018 probes (1 sample was removed by the authors prior to uploading the
dataset on GEO).

Note that in the following, we assume that the user has access to a data
folder `data/shoemaker2015/rawdata`, containing the microarray data. 

```{r}
data_dir = "data/shoemaker2015/rawdata"
```

Given the source and a `Targets.txt` structured as follows, microarray can be
loaded thanks to the limma library.

```
FileName
GSM1557140_AR0313_043raw.txt.gz
GSM1557141_AR0313_044raw.txt.gz
GSM1557142_AR0313_045raw.txt.gz
GSM1557143_AR0313_055raw.txt.gz
GSM1557144_AR0313_056raw.txt.gz
GSM1557145_AR0313_057raw.txt.gz
GSM1557146_AR0313_058raw.txt.gz
GSM1557147_AR0313_059raw.txt.gz
```

```{r message=FALSE, results="hide", warning=FALSE}
targets = limma::readTargets()
RG = limma::read.maimages(
  targets, source="agilent",
  path=data_dir,
  other.columns="gIsWellAboveBG",
  green.only=TRUE)

```

The normalization strategy we apply here relies on `limma` and is as follows:

  - First, normalize probe intensity using background information using the
    "norm-exponential" strategy.
  - Then normalize across micro-arrrays using quantile normalization.



```{r reading_targets, results="hide", fig.width=4, fig.height=2, message=FALSE, warning=FALSE}
# Perform background correction using norm-exponential strategy and normalize
# across samples using quantile normalization.
RG = limma::backgroundCorrect(RG, method="normexp")
RG.q = limma::normalizeBetweenArrays(RG, method="quantile")
```

Plotting the smoothed empirical densities of the probe values before
normalization shows considerable variations betweens arrays. Once the data has
been normalized across array using quantile normalization, the smoothed
empirical densities of each sample perfectly overlap.

```{r plotting_densities, results="hide", fig.width=6, fig.height=3}
# Plot the densities of the probes before and after normalization.
par(mfrow=c(1, 2), mar=c(2.0, 2.0, 2.0, 2.0))
limma::plotDensities(RG, col="black", legend=FALSE,
		     main="Before normalization", cex=0.8)
limma::plotDensities(RG.q, col="black", legend=FALSE,
		     main="After normalization", cex=0.8)
```


```{r echo=FALSE, results="hide"}
# Get the number for the text. Do not display results or computation
control_probes = RG.q$genes[, "ControlType"] == 1
is_expressed = rowSums(RG.q$other$"gIsWellAboveBG" > 0) >= 4
n_control_probes = sum(control_probes)
n_lowly_expressed = sum(!is_expressed)
```

We then clean up the names of each gene and each sample to match the original
data. Finally, we further filter out probes based on the following criteria:
(1) removing the `r n_control_probes` control probes; (2) removing 
`r n_lowly_expressed` low-expressed genes. 

```{r clean_up_names}

sample_names = sapply(strsplit(colnames(RG.q), "_"), .subset2,  1)
colnames(RG.q) = sample_names
row.names(RG.q) = make.names(RG$genes$SystematicName, unique=TRUE)
idx_to_keep = which(
  !(RG$genes$Systematic %in% c("DarkCorner", "GE_BrightCorner",
			       "NegativeControl")))

data = RG.q[idx_to_keep,]

# Filter out control probes.
control_probes = data$genes[, "ControlType"] == 1
is_expressed = rowSums(data$other$"gIsWellAboveBG" > 0) >= 4

data = data[!control_probes & is_expressed, ]$E
```



```{r echo=FALSE, results="hide"}
# Do not display. setting variables for text
n_samples = dim(data)[2]
n_probes = dim(data)[1]
```

After filtering, we are left with `r n_probes` probes of interest in 
`r n_samples` samples.


Now that we have normalized and filtered the gene expressions, let's load the
metadata. The package `moanin` contains the normalized data and meta of
[@shoemaker:ultrasensitive].

```{r}
# Now load in the metadata
data(shoemaker2015)
meta = shoemaker2015$meta
data = shoemaker2015$data
```

