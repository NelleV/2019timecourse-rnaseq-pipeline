\documentclass[9pt,a4paper,]{extarticle}

\usepackage{f1000_styles}

\usepackage[pdfborder={0 0 0}]{hyperref}

\usepackage[numbers]{natbib}
\bibliographystyle{unsrtnat}


%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}

% disable code chunks background
%\renewenvironment{Shaded}{}{}

% disable section numbers
\setcounter{secnumdepth}{0}

\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}


\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}

\begin{document}
\pagestyle{front}

\title{A pipeline to analyse time-course gene expression data}

%% AUTH AFFIL %%

\maketitle
\thispagestyle{front}

\begin{abstract}
The phenotypic diversity of cells is governed by a complex equilibrium between their genetic identity and their environmental interactions: Understanding the dynamics of gene expression is a fundamental question of biology.However, analysing time-course transcriptomic data raises unique challenging statistical and computational questions, requiring the development of novel methods and software. Using as case study time-course transcriptomics data from mice exposed to different strains of influenza, this workflows provides a step-by-step tutorial of the methodology used to analyse time-course data: (1) normalization of the micro-array dataset; (2) differential expression analysis using functional data analysis; (3) clustering fo time-course data; (4) interpreting clusters with GO term and KEGG pathway enrichment analysis.
\end{abstract}

\section*{Keywords}
time-course gene expression data, clustering, differential expression, workflow


\clearpage
\pagestyle{main}

\#TODO list

\begin{itemize}
\tightlist
\item
  Add legends to the plots that don't have.
\item
  Currently have two functions ``plot\_genes'', ``plot\_centroids'', that do exactly
  the same thing. Find a better name for both of them
\item
  switch to camel case function names
\item
  Remove the namespace call
\item
  Make clear that it applies to RNASeq and how to call the different functions
  to RNASeq
\item
  Check that clustering can deal with count data.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(devtools)}
\KeywordTok{install_github}\NormalTok{(}\StringTok{"NelleV/moanin"}\NormalTok{, }\DataTypeTok{dependencies=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   
   checking for file '/tmp/RtmpsJhqa7/remotes352cb8e01/NelleV-moanin-205e154/DESCRIPTION' ...
  
v  checking for file '/tmp/RtmpsJhqa7/remotes352cb8e01/NelleV-moanin-205e154/DESCRIPTION'
## 
  
-  preparing 'moanin':
##    checking DESCRIPTION meta-information ...
  
v  checking DESCRIPTION meta-information
## 
  
-  checking for LF line-endings in source and make files and shell scripts
## 
  
-  checking for empty or unneeded directories
## -  looking to see if a 'data/datalist' file should be added
## 
  
-  building 'moanin_0.0.0.tar.gz' (3.7s)
## 
  
   
## 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(moanin)}
\end{Highlighting}
\end{Shaded}

EAP:

\begin{itemize}
\tightlist
\item
  Do we need installation instructions for moanin in this document, since its
  not on CRAN/bioconductor? Also, how its set up now (doing make file, which
  compiles the documentation, etc), probably prohibits use of, e.g.
  \texttt{install\_github} from \texttt{devtools}. If able to call
  \texttt{install\_github("NelleV/2019timecourse-rnaseq-pipeline",\ subdir="bin/moanin",\ dependencies=TRUE)} would be simpler (would also
  install the dependencies and get around problems in script)
\item
  I got an error in installation script for packages:
\end{itemize}

\begin{verbatim}
epurdom-0:2019timecourse-rnaseq-pipeline epurdom$ Rscript scripts/install.R
Loading required package: devtools
Loading required package: usethis
Loading required package: ggfortify
Loading required package: ggplot2
Loading required package: kableExtra
Error in contrib.url(repos, "source") : 
  trying to use CRAN without setting a mirror
Calls: install.packages -> contrib.url
In addition: Warning message:
In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
  there is no package called <e2><80><98>kableExtra<e2><80><99>
Execution halted
\end{verbatim}

\begin{itemize}
\item
  \texttt{biocLite} is no longer the recommended way to install bioconductor. Instead
  \texttt{BiocManager::install(c("edge",\ "NMI"))}. But this is dependent on
  bioconductor/R version. Also, now that docker, can you change the
  installation to just be simple one-liner (and \texttt{BiocManager::install} can
  also do non-bioc packages, and is much more reliable.)
\item
  I get multiple errors in compilation of file. Not sure, however, why
  TravisCI didn't hit these problems, so you might want to see what's going on
  there. Probably caching or something, so might want to occassionally remove
  the cache and run again, if TravisCI is saving the cache. One error I fixed,
  but wasn't sure about this error (changed it to \texttt{entrezgene\_id} and seems to
  be running now\ldots{}):
\end{itemize}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Gene expression studies provide simultaneous quantification of the level of
mRNA from all genes in a sample. High-throughput studies of gene expression
have a long history, starting with microarray technologies in the 1990s
through to single-cell technologies. While many expression studies are
designed to compare the gene expression between distinct groups, there is also a
long history of time-course expression studies. Such studies compare the gene expression
across time by measuring mRNA levels from samples collected at different timepoints \footnote{Because the collection of the mRNA is often destructive, samples at
  different time points are generally from different biological samples;
  longitudinal studies, for example tracking the same subject over time, are
  certainly possible, but not directly considered here.}. Such time-course studies can vary from measuring a few distinct time
points, to sampling ten to twenty time points. These longer time series are
particularly interested in investigating development over time. More recently,
a new variety of time course studies have come from single-cell sequencing experiments\textbf{EAP: need citation} which can sequencing single cells which are at different stages of development; in this case, the time point is the stage of the cell in the process of development -- a
value that is not know but estimated from the data as its ``pseudo-time.''

While there are many methods that have been proposed for discrete aspects of
time course data, the entire workflow for analysis of such data remains
difficult, particularly for long, developmental time series. Most methods
proposed for time course data are concerned with detecting genes that are
changing over time (differential expression analysis), examples being \texttt{edge}
\citep{storey:significance}, functional component analysis based models \citep{wu:more},
time-course permutation tests \citep{park:statistical}, and multiple testing
strategies to combine single time point differential expression analysis
\citep{sun:multiple}. However, with long time course datasets, particularly in
developmental systems, a massive number of genes will show \emph{some} change. For
example, in a study of mice lung tissues infected with influenza that we consider in this workflow, over 50\% of genes
are shown to be changing over time. The task in these settings is often not to
detect changes in genes, but to categorize them into biologically interpretable
patterns.

We present here a workflow for such an analysis that consists of 4 main
parts (Figure \ref{fig:schema}):

\begin{itemize}
\tightlist
\item
  Quality control and normalization;
\item
  Identification of genes that are differentially expressed;
\item
  Clustering of genes into distinct temporal patterns;
\item
  Biological interpretation of the clusters.
\end{itemize}

This workflow represents an integration of both novel implementations of
previously established methods and new methodologies for the settings of
developmental time series. It relies on several standard packages for
analysing gene expression data, some specific for time-course data, others
broadly used by the community. We provide the various steps of the workflow as
functions in a R package called \texttt{moanin}.

\begin{figure}

{\centering \includegraphics[width=4.81in]{images/fig1_schemas} 

}

\caption{Workflow for analyzing time-course datasets.}\label{fig:schema}
\end{figure}

\hypertarget{analysis-of-the-dynamical-response-of-mouse-lung-tissue-to-influenza}{%
\section{Analysis of the dynamical response of mouse lung tissue to influenza}\label{analysis-of-the-dynamical-response-of-mouse-lung-tissue-to-influenza}}

This workflow is illustrated using data from a micro-array time-course
experiment, exposing mice to three different strains of influenza, and
collecting lung tissue during 14 time-points after infection (0, 3, 6, 9, 12,
18, 24, 30, 36, 48, 60 hours, then 3, 5, and 7 days later)
\citep{shoemaker:ultrasensitive}. The three strains of influenza used in the
study are (1) a low pathogenicity seasonal H1N1 influenza virus
(A/Kawasaki/UTK4/2009 {[}H1N1{]}), a mildly pathogenic virus from the 2009
pandemic season (A/California/04/2009 {[}H1N1{]}), and a highly pathogenic H5N1
avian influenza virus (A/Vietnam/1203/2004 {[}H5N1{]}. Mice were injected with
\(10^5\) PFU of each virus. An adidtional 42 mice were injected with a lower dose
of the Vietnam avian influenza virus (\(10^3\) PFU).

\textbf{EAP: We need to add comment about microarray versus sequencing data}

By combining gene expression time-course data with virus growth data, the
authors show that the inflammatory response of lung tissue is gated until a
threshold of the virus concentration is exceeded in the lung. Once this
threshold is exceeded, a strong inflammatory and cytokin production occurs.
This results provides evidence that the pathology response is non-linearly
regulated by virus concentration.

\hypertarget{quality-control-and-normalization}{%
\subsection{Quality control and normalization}\label{quality-control-and-normalization}}

The first steps of analysis of gene expression data is always to do
normalization and quality control checks of the data. In what follows, we show
an example of this for the influenza data using generic methods; these steps
are not in specific to time course data, but could be done for any gene expression
analysis.

First let's load the data. The package \texttt{moanin} contains the normalized
data and metadata of \citep{shoemaker:ultrasensitive}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Now load in the metadata}
\KeywordTok{data}\NormalTok{(shoemaker2015)}
\NormalTok{meta =}\StringTok{ }\NormalTok{shoemaker2015}\OperatorTok{$}\NormalTok{meta}
\NormalTok{data =}\StringTok{ }\NormalTok{shoemaker2015}\OperatorTok{$}\NormalTok{data}
\end{Highlighting}
\end{Shaded}

\hypertarget{exploratory-analysis-and-quality-control}{%
\subsubsection{Exploratory analysis and quality control}\label{exploratory-analysis-and-quality-control}}

Typically, two quality control and exploratory analysis steps are also
performed before and after normalization: (1) low dimensionality embedding of
the samples; (2) correlation plots between each samples. In both cases, we
expect a strong biological signal, while replicate samples should be strongly
clustered or correlated with one another.

Before performing any additional exploratory analysis, let us only keep highly
variable genes: we keep for this step only the top 50\% most variable genes.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{variance_cutoff =}\StringTok{ }\FloatTok{0.5}
\NormalTok{variance_per_genes =}\StringTok{ }\KeywordTok{apply}\NormalTok{(data, }\DecValTok{1}\NormalTok{, mad)}
\NormalTok{min_variance =}\StringTok{ }\KeywordTok{quantile}\NormalTok{(variance_per_genes, }\KeywordTok{c}\NormalTok{(variance_cutoff))}
\NormalTok{variance_filtered_data =}\StringTok{ }\NormalTok{data[variance_per_genes }\OperatorTok{>}\StringTok{ }\NormalTok{min_variance,]}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/unnamed-chunk-6-1} \end{center}

Let us first perform the PCA analysis. Here, we perform a PCA of rank 3 of the
centered and scaled gene expression data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Reorder genes on condition, time, and replicate}

\NormalTok{pca_data =}\StringTok{ }\KeywordTok{prcomp}\NormalTok{(}\KeywordTok{t}\NormalTok{(variance_filtered_data), }\DataTypeTok{rank=}\DecValTok{3}\NormalTok{, }\DataTypeTok{center=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{scale=}\OtherTok{TRUE}\NormalTok{) }
\NormalTok{percent_var =}\StringTok{ }\KeywordTok{round}\NormalTok{(}\DecValTok{100} \OperatorTok{*}\StringTok{ }\KeywordTok{attr}\NormalTok{(pca_data, }\StringTok{"percentVar"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

We then plot the two first components, and color each sample by (1) its
condition; (2) its sampling time. We use different markers for each replicate. \textbf{EAP: Unclear what `markers' refers to}
We also plot the second and third components in the second row.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\DataTypeTok{mar=}\KeywordTok{c}\NormalTok{(}\FloatTok{2.5}\NormalTok{, }\FloatTok{2.5}\NormalTok{, }\FloatTok{2.5}\NormalTok{, }\FloatTok{2.5}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(}
\NormalTok{    pca_data}\OperatorTok{$}\NormalTok{x[, }\StringTok{"PC2"}\NormalTok{], pca_data}\OperatorTok{$}\NormalTok{x[, }\StringTok{"PC1"}\NormalTok{],}
    \DataTypeTok{col=}\NormalTok{ann_colors}\OperatorTok{$}\NormalTok{Group[meta}\OperatorTok{$}\NormalTok{Group],}
    \DataTypeTok{pch=}\NormalTok{ann_markers}\OperatorTok{$}\NormalTok{Replicate[}\KeywordTok{as.factor}\NormalTok{(meta}\OperatorTok{$}\NormalTok{Replicate)],}
    \DataTypeTok{xlab=}\StringTok{"PC2"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"PC1"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(}
\NormalTok{    pca_data}\OperatorTok{$}\NormalTok{x[, }\StringTok{"PC2"}\NormalTok{], pca_data}\OperatorTok{$}\NormalTok{x[, }\StringTok{"PC1"}\NormalTok{],}
    \DataTypeTok{col=}\NormalTok{ann_colors}\OperatorTok{$}\NormalTok{Timepoint[}\KeywordTok{as.factor}\NormalTok{(meta}\OperatorTok{$}\NormalTok{Timepoint)],}
    \DataTypeTok{pch=}\NormalTok{ann_markers}\OperatorTok{$}\NormalTok{Replicate[}\KeywordTok{as.factor}\NormalTok{(meta}\OperatorTok{$}\NormalTok{Replicate)],}
    \DataTypeTok{xlab=}\StringTok{"PC2"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"PC1"}\NormalTok{)}

\KeywordTok{plot}\NormalTok{(}
\NormalTok{    pca_data}\OperatorTok{$}\NormalTok{x[, }\StringTok{"PC2"}\NormalTok{], pca_data}\OperatorTok{$}\NormalTok{x[, }\StringTok{"PC3"}\NormalTok{],}
    \DataTypeTok{col=}\NormalTok{ann_colors}\OperatorTok{$}\NormalTok{Group[meta}\OperatorTok{$}\NormalTok{Group],}
    \DataTypeTok{pch=}\NormalTok{ann_markers}\OperatorTok{$}\NormalTok{Replicate[}\KeywordTok{as.factor}\NormalTok{(meta}\OperatorTok{$}\NormalTok{Replicate)],}
    \DataTypeTok{xlab=}\StringTok{"PC2"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"PC3"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(}
\NormalTok{    pca_data}\OperatorTok{$}\NormalTok{x[, }\StringTok{"PC2"}\NormalTok{], pca_data}\OperatorTok{$}\NormalTok{x[, }\StringTok{"PC3"}\NormalTok{],}
    \DataTypeTok{col=}\NormalTok{ann_colors}\OperatorTok{$}\NormalTok{Timepoint[}\KeywordTok{as.factor}\NormalTok{(meta}\OperatorTok{$}\NormalTok{Timepoint)],}
    \DataTypeTok{pch=}\NormalTok{ann_markers}\OperatorTok{$}\NormalTok{Replicate[}\KeywordTok{as.factor}\NormalTok{(meta}\OperatorTok{$}\NormalTok{Replicate)],}
    \DataTypeTok{xlab=}\StringTok{"PC2"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"PC3"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/pca_plots-1} \end{center}

Then, we plot the pearson correlation across each samples. We order the
samples by their Group (treatment) and Timepoint (the time of sampling).
Additionally, in this example, we order each treatment by strength of the
pathogenicity of the treatment: Control, Kawasaki, California, low dose of
Vietnam, then high dose of Vietnam.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Reorder the conditions such that:}
\CommentTok{#   - Control is before any influenza treatment}
\CommentTok{#   - Each treatment is ordered from low to high pathogeny}
\NormalTok{meta}\OperatorTok{$}\NormalTok{Group =}\StringTok{ }\KeywordTok{factor}\NormalTok{(meta}\OperatorTok{$}\NormalTok{Group, }\KeywordTok{levels}\NormalTok{(meta}\OperatorTok{$}\NormalTok{Group)[}\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{)])}

\CommentTok{# Reorder genes on condition, time, and replicate}
\NormalTok{ord =}\StringTok{ }\KeywordTok{order}\NormalTok{(}
\NormalTok{  meta}\OperatorTok{$}\NormalTok{Group,}
\NormalTok{  meta}\OperatorTok{$}\NormalTok{Timepoint,}
\NormalTok{  meta}\OperatorTok{$}\NormalTok{Replicate)}

\NormalTok{variance_filtered_data =}\StringTok{ }\NormalTok{variance_filtered_data[, ord]}
\NormalTok{data_corr =}\StringTok{ }\KeywordTok{cor}\NormalTok{(variance_filtered_data, }\DataTypeTok{method=}\StringTok{"pearson"}\NormalTok{)}
\NormalTok{data_corr_meta =}\StringTok{ }\NormalTok{meta[ord, ]}
\NormalTok{data_corr_meta}\OperatorTok{$}\NormalTok{Timepoint =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(data_corr_meta}\OperatorTok{$}\NormalTok{Timepoint)}

\KeywordTok{aheatmap}\NormalTok{(}
\NormalTok{    data_corr,}
    \DataTypeTok{Colv=}\OtherTok{NA}\NormalTok{, }\DataTypeTok{Rowv=}\OtherTok{NA}\NormalTok{,}
    \DataTypeTok{annCol=}\NormalTok{data_corr_meta[, }\KeywordTok{c}\NormalTok{(}\StringTok{"Group"}\NormalTok{, }\StringTok{"Timepoint"}\NormalTok{)],}
    \DataTypeTok{annRow=}\NormalTok{data_corr_meta[, }\KeywordTok{c}\NormalTok{(}\StringTok{"Group"}\NormalTok{, }\StringTok{"Timepoint"}\NormalTok{)],}
    \DataTypeTok{annLegend=}\OtherTok{TRUE}\NormalTok{, }
    \DataTypeTok{annColors=}\NormalTok{ann_colors,}
    \DataTypeTok{main=}\StringTok{"Correlation plot"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/correlation_plot-1} \end{center}

We can already see interesting patterns emerging from the correlation plot.
First, the cross-correlation amongst samples taking from the control mice is
higher than the cross correlation amongst the rest of the treatments. Second,
the influenza-infected mice midly react until time point 36. Third, the less
pathogenic the strain is, the closer the samples are to the control condition.
Fourth, the Vietnam samples at time point 120 and 168 are the one that are the
most different from control samples.

\hypertarget{differential-expression-analysis-of-time-course-data}{%
\subsection{Differential expression analysis of time-course data}\label{differential-expression-analysis-of-time-course-data}}

\hypertarget{approaches-to-de-analysis-in-time-course-data}{%
\subsubsection{Approaches to DE analysis in time-course data}\label{approaches-to-de-analysis-in-time-course-data}}

The next step in a gene expression analysis is typically to run a differential
expression analysis, generally to find genes different between different
conditions. For time-course data, there are two different approaches for
determining differentially expressed genes,

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  Per-time point analysis, where we consider each time point a different
  condition and determine what genes are changing between time points, or
  between conditions at a single time-point.
\item
  Global analysis, where we consider the expression pattern globally over
  time, and consider what genes have either different patterns between
  conditions or a changing pattern (i.e.~non-constant) over time. A common
  approach first step is to fit a spline model to each gene
  \citep{storey:significance},
  and then use that spline model to test for different kinds of differential
  expression across time.
\end{enumerate}

The per-time point analysis is using classical differential expression
approaches, and is often the approach advocated when dealing with small
time-course datasets, where there are only a few time points
\citep[\citet{robinson:edgeR}, \citet{love:moderated}]{ritchie:limma} . For long time-course datasets,
however, a separate test for each time-point results in creating many
different tests, for example one for every time point, the results of which
are difficult to integrate. We find in practice that the global analysis
simplifies analysis and of longer time courses data, with per-time point
analysis reserved for particularly interesting comparisons of individual
time-points.

We note that we could have time course data on either a single condition or
time course data on multiple conditions (such as the influenza dataset we are
considering), which will alter slightly the types of questions we are
interested in, but the two basic approaches remains the same. In what follows,
we will focus on the situation where we have multiple conditions. \textbf{EAP: Any
reason one and not the other. Maybe should change this sentence}

\textbf{Use with \texttt{moanin}} \texttt{moanin} provides functionality for performing both of
these types of approaches, though our focus is on the global approach. In both
situations, we first need to set up a object (a \texttt{splines\_model} object) to
hold the meta data, as well as information for fitting the spline model.

We start by creating the \texttt{splines\_model} object using the
\texttt{create\_splines\_model} function. The \texttt{splines\_model} object contains a number
of metadata and options used throughout this analysis: the condition and
timepoints of each samples, the formula object used or the basis or the
degrees of freedom of the model. The metadata data.frame object should
contain at least two columns: one named \texttt{Group}, containing the treatement
effect, and a second one named \texttt{Timepoint} containing the timepoint
information.

\begin{tabular}{l|r|l|r|r}
\hline
  &  & Group & Replicate & Timepoint\\
\hline
GSM1557140 & 0 & K & 1 & 0\\
\hline
GSM1557141 & 1 & K & 2 & 0\\
\hline
GSM1557142 & 2 & K & 3 & 0\\
\hline
GSM1557143 & 3 & K & 1 & 12\\
\hline
GSM1557144 & 4 & K & 2 & 12\\
\hline
GSM1557145 & 5 & K & 3 & 12\\
\hline
\end{tabular}

If no formula is provided, it will default to the following:
\texttt{formula\ =\ \textasciitilde{}Group:ns(Timepoint,\ df=degrees\_of\_fredoom)\ +\ Group\ +\ 0}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{splines_model =}\StringTok{ }\KeywordTok{create_splines_model}\NormalTok{(meta, }\DataTypeTok{degrees_of_freedom=}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Here we have provided the meta data that defines\ldots{} \texttt{create\_splines\_model}
will \ldots{}. \textbf{FIXME add information about what meta data is expected, describe
what \texttt{create\_splines\_model} does (does it fit the splines? Just hold create an
object? Create basis functions?)}.

\textbf{EAP: General comment: you need a few more print() and head() of some objects to demonstrate what the output looks like}

\hypertarget{weekly-differential-expression-analysis}{%
\subsubsection{Weekly differential expression analysis}\label{weekly-differential-expression-analysis}}

\texttt{moanin} provides a simple interface to perform a timepoint by timepoint
differential expression analysis. This is traditionally done by the user
defining the comparisons (called \texttt{contrasts} in linear models). Under the
hood, simply calls \texttt{limma} \citep{ritchie:limma} on the set of contrasts provided.
By default, it expects RNA-Seq contact counts, and will estimate voom weights.
We tern

Here, we show an example where we define our contrasts to be the difference
between the control mouse (``M'') and the mouse infected with the high dose of
the influenza strain A/Vietnam/1203/04 (H5N1) (``VL'') for each time point, but
the function works with any form contrasts \citep{ritchie:limma}.

First, create the contrasts for all timepoints between the two groups of
interest:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{contrasts =}\StringTok{ }\KeywordTok{create_timepoints_contrasts}\NormalTok{(}\StringTok{"M"}\NormalTok{, }\StringTok{"VL"}\NormalTok{, splines_model)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l}
\hline
x\\
\hline
M.0-VL.0\\
\hline
M.3-VL.3\\
\hline
M.6-VL.6\\
\hline
M.9-VL.9\\
\hline
M.12-VL.12\\
\hline
M.18-VL.18\\
\hline
M.24-VL.24\\
\hline
M.30-VL.30\\
\hline
M.36-VL.36\\
\hline
M.48-VL.48\\
\hline
M.60-VL.60\\
\hline
M.72-VL.72\\
\hline
M.120-VL.120\\
\hline
M.168-VL.168\\
\hline
\end{tabular}

Then run the differential expression analysis on all of those timepoints
jointly.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Define contrast   }
\NormalTok{weekly_de_analysis =}\StringTok{ }\KeywordTok{DE_timepoints}\NormalTok{(}
\NormalTok{     data, splines_model, contrasts,}
     \DataTypeTok{use_voom_weights=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
\hline
  & M.0-VL.0-pval & M.0-VL.0-qval & M.0-VL.0-lfc & M.3-VL.3-pval & M.3-VL.3-qval & M.3-VL.3-lfc & M.6-VL.6-pval & M.6-VL.6-qval & M.6-VL.6-lfc & M.9-VL.9-pval & M.9-VL.9-qval & M.9-VL.9-lfc & M.12-VL.12-pval & M.12-VL.12-qval & M.12-VL.12-lfc & M.18-VL.18-pval & M.18-VL.18-qval & M.18-VL.18-lfc & M.24-VL.24-pval & M.24-VL.24-qval & M.24-VL.24-lfc & M.30-VL.30-pval & M.30-VL.30-qval & M.30-VL.30-lfc & M.36-VL.36-pval & M.36-VL.36-qval & M.36-VL.36-lfc & M.48-VL.48-pval & M.48-VL.48-qval & M.48-VL.48-lfc & M.60-VL.60-pval & M.60-VL.60-qval & M.60-VL.60-lfc & M.72-VL.72-pval & M.72-VL.72-qval & M.72-VL.72-lfc & M.120-VL.120-pval & M.120-VL.120-qval & M.120-VL.120-lfc & M.168-VL.168-pval & M.168-VL.168-qval & M.168-VL.168-lfc\\
\hline
NM\_009912 & 0.2728476 & 0.4745864 & 2.2018266 & 0.7670600 & 0.8760739 & 1.1576881 & 0.0514865 & 0.1487818 & 2.5397431 & 0.1461489 & 0.3125183 & -0.7613983 & 0.2735411 & 0.4753685 & 1.4786596 & 0.5199686 & 0.7057241 & 1.0838768 & 0.0372513 & 0.1172476 & 1.0099581 & 0.1663710 & 0.3415394 & -2.0803981 & 0.0040198 & 0.0209941 & 1.867318 & 0.0000272 & 0.0003259 & -2.877945 & 0.0000001 & 0.0000025 & -2.200448 & 0.0000000 & 0.0000000 & -2.941491 & 0.0000000 & 0.0000000 & 2.659545 & 0.0000000 & 0.0000000 & -4.846082\\
\hline
NM\_008725 & 0.8508522 & 0.9242869 & 2.0281764 & 0.1390300 & 0.3020872 & 1.4568427 & 0.0034217 & 0.0184668 & 2.3999010 & 0.0011765 & 0.0078218 & -0.5946375 & 0.2218494 & 0.4142375 & 0.8974352 & 0.0490869 & 0.1436339 & 1.0689628 & 0.0001128 & 0.0011050 & -1.1910616 & 0.2358903 & 0.4313519 & 0.8409000 & 0.0025790 & 0.0147499 & 1.463357 & 0.0000005 & 0.0000098 & -3.732241 & 0.0992368 & 0.2386529 & -3.305718 & 0.2451045 & 0.4423855 & -5.832292 & 0.0028580 & 0.0160083 & 5.103924 & 0.3298546 & 0.5356392 & 6.770567\\
\hline
NM\_007473 & 0.0880394 & 0.2192542 & 0.6779618 & 0.9165990 & 0.9592675 & 0.7639279 & 0.6859316 & 0.8250549 & 1.2874572 & 0.4958553 & 0.6863397 & -0.9545717 & 0.9654288 & 0.9838265 & 1.1610592 & 0.0996542 & 0.2393445 & -0.5791692 & 0.3501431 & 0.5558993 & -0.7342619 & 0.9783036 & 0.9900678 & 0.8829109 & 0.9915772 & 0.9963117 & -3.926817 & 0.7895585 & 0.8895260 & -3.706969 & 0.5164039 & 0.7028663 & -2.200317 & 0.0909694 & 0.2244290 & 2.218886 & 0.6982871 & 0.8331540 & -1.433851 & 0.6691637 & 0.8141329 & 7.711609\\
\hline
ENSMUST00000094955 & 0.0081879 & 0.0367991 & 1.1856925 & 0.9353016 & 0.9690575 & -0.6333013 & 0.3745215 & 0.5795488 & 2.5957177 & 0.0050684 & 0.0252354 & -0.6988290 & 0.6729944 & 0.8166022 & 1.0178334 & 0.0948389 & 0.2310919 & 0.8228212 & 0.0253932 & 0.0879330 & 1.1482199 & 0.3657233 & 0.5710470 & -1.3750913 & 0.2915369 & 0.4951562 & -3.968832 & 0.5819450 & 0.7532377 & -1.276993 & 0.6373529 & 0.7923844 & 1.548320 & 0.8614351 & 0.9300767 & -4.288514 & 0.8886550 & 0.9448186 & -4.232771 & 0.1879584 & 0.3707972 & 6.442072\\
\hline
NM\_001042489 & 0.4191775 & 0.6208106 & 1.2123141 & 0.7607212 & 0.8723405 & 0.5992596 & 0.7748772 & 0.8807955 & 1.1476237 & 0.1995820 & 0.3858600 & 2.6613947 & 0.0205303 & 0.0748885 & -0.8188268 & 0.1910652 & 0.3748543 & -0.5443243 & 0.8270177 & 0.9111679 & 2.7899965 & 0.5239967 & 0.7088274 & -1.3479903 & 0.1409795 & 0.3049960 & -6.548630 & 0.4062041 & 0.6090027 & 1.889101 & 0.4968748 & 0.6871546 & -3.392918 & 0.0003701 & 0.0030031 & -6.639293 & 0.0000135 & 0.0001774 & -5.488106 & 0.0256136 & 0.0884953 & -4.976920\\
\hline
NM\_008159 & 0.1231754 & 0.2777536 & 1.1022344 & 0.1169243 & 0.2678638 & 0.7374376 & 0.5781815 & 0.7504472 & 0.9406648 & 0.0059119 & 0.0284812 & -0.8908867 & 0.4381368 & 0.6375400 & 1.2644788 & 0.8998830 & 0.9506910 & -0.5490689 & 0.5634704 & 0.7394176 & -1.4223473 & 0.5015939 & 0.6910094 & -2.3313130 & 0.0000000 & 0.0000000 & 1.321606 & 0.0000000 & 0.0000001 & -2.339338 & 0.0000000 & 0.0000000 & -3.096598 & 0.0000007 & 0.0000123 & -5.350299 & 0.0000125 & 0.0001658 & -6.076895 & 0.0000010 & 0.0000176 & -4.774939\\
\hline
NM\_001013813 & 0.0565287 & 0.1593800 & 0.6299949 & 0.1710643 & 0.3480241 & 0.9746582 & 0.0951123 & 0.2315686 & 3.3644621 & 0.4387357 & 0.6380771 & 0.7308201 & 0.0005373 & 0.0040980 & 1.2229788 & 0.3295522 & 0.5353121 & 1.7341606 & 0.0007915 & 0.0056472 & -1.0267100 & 0.0013222 & 0.0086036 & -0.9327780 & 0.0010519 & 0.0071337 & 1.314872 & 0.1685588 & 0.3445806 & 1.623828 & 0.0554666 & 0.1571666 & -4.828044 & 0.0067413 & 0.0315747 & -5.772946 & 0.0006393 & 0.0047334 & -5.776763 & 0.0004591 & 0.0035968 & -5.017664\\
\hline
AK039774 & 0.0150416 & 0.0590150 & 0.6372239 & 0.0622016 & 0.1707939 & 0.9714819 & 0.0038649 & 0.0203447 & 1.3168792 & 0.9071986 & 0.9543873 & -0.6495320 & 0.0337680 & 0.1089499 & 1.4620498 & 0.1808765 & 0.3613288 & -0.6084973 & 0.4268483 & 0.6276079 & -1.4219238 & 0.8931509 & 0.9471666 & 0.6812377 & 0.3320222 & 0.5378422 & 1.725274 & 0.0000084 & 0.0001177 & 2.756976 & 0.7523631 & 0.8671706 & -4.265131 & 0.0000850 & 0.0008681 & -5.010475 & 0.0000014 & 0.0000238 & -4.623531 & 0.0066328 & 0.0311737 & -4.795976\\
\hline
NM\_013782 & 0.8754233 & 0.9377109 & 0.5940058 & 0.0001107 & 0.0010876 & 1.1803029 & 0.4731855 & 0.6676244 & 1.9274813 & 0.3558245 & 0.5614957 & -0.6697288 & 0.0000009 & 0.0000157 & 1.2377208 & 0.0469473 & 0.1390186 & -1.2969383 & 0.0877739 & 0.2187959 & 0.7832039 & 0.0873966 & 0.2181127 & -0.7705369 & 0.3054160 & 0.5099832 & 1.240504 & 0.0593928 & 0.1651796 & 2.355748 & 0.4210031 & 0.6224586 & -3.879986 & 0.0053367 & 0.0262800 & -5.108367 & 0.0056116 & 0.0273406 & -4.262393 & 0.0042107 & 0.0217896 & -4.617477\\
\hline
NM\_028622 & 0.7667946 & 0.8759265 & 1.6477918 & 0.9457494 & 0.9741115 & -1.8648471 & 0.9903079 & 0.9957216 & 1.1660022 & 0.6332637 & 0.7895226 & 2.1081788 & 0.8592452 & 0.9288844 & 1.2212238 & 0.7658228 & 0.8753935 & -1.1079164 & 0.8331999 & 0.9145679 & -0.8793087 & 0.8359000 & 0.9160123 & -1.2284455 & 0.8894396 & 0.9452334 & 1.160648 & 0.5797431 & 0.7516226 & -3.323953 & 0.5675779 & 0.7424636 & -4.125536 & 0.6699768 & 0.8146554 & -6.126729 & 0.6521300 & 0.8025109 & -4.510424 & 0.8460618 & 0.9215885 & 6.351333\\
\hline
\end{tabular}

We can repeat this for each of the conditions

Let's look at the distribution of genes found differentially expressed per
week between control and each of the influenza strains.

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/unnamed-chunk-12-1} \end{center}

The distribution of number of genes found differentially expressed by
considering each time-point independantly highlights the challenges of such
approach. Timepoint 6H and 18H of the Kawasaki strain have fewer numbers of
genes found differentially expressed than timepoints 3H and 9H: this is likely
due to biological or technical variances for specific genes at specific
timepoints. \textbf{EAP: We should add more to this}

As a summary, classic differential expression methods are appropriate for
unordered treatments, but fail to use the temporal structure of the data.

\hypertarget{time-course-differential-expression-analysis-between-two-groups}{%
\subsubsection{Time-course differential expression analysis between two groups}\label{time-course-differential-expression-analysis-between-two-groups}}

To leverage this temporal structure, Storey et al \citep{storey:significance}
proposed to model each gene in time-course micro-array with a splines
function, and to use a log-ratio likelihood test to detect differentially
expressed genes.

\texttt{moanin} extends this idea by providing functionality to compare time course
data between different treatment conditions, using a similar mechanism of
contrasts -- only now the contrasts are differences between the estimated
means.

\textbf{FIXME add in equations, like from the EPICON paper, to describe them mathematically}

\textbf{EAP: Do we need this call to limma by the user, or can these not be done
internally by the \texttt{timecourse\_differential\_expression\_analysis} function? We
can still preserve the option of user defining their own, but would be nicer
to make this simpler for the user (e.g.~an if clause that tests whether input
is matrix or character vector)}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Differential expression analysis}
\NormalTok{timecourse_contrasts =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"M-K"}\NormalTok{, }\StringTok{"M-C"}\NormalTok{, }\StringTok{"M-VL"}\NormalTok{, }\StringTok{"M-VH"}\NormalTok{)}

\NormalTok{contrasts =}\StringTok{ }\KeywordTok{makeContrasts}\NormalTok{(}
    \DataTypeTok{contrasts=}\NormalTok{timecourse_contrasts,}
    \DataTypeTok{levels=}\KeywordTok{levels}\NormalTok{(meta}\OperatorTok{$}\NormalTok{Group))}

\CommentTok{# The function takes the data (data.frame or named matrix), the meta data}
\CommentTok{# (data.frame containing a timepoint and group column, the first corresponding}
\CommentTok{#<c2><a0>to the time-course information, the latter corresponding to the}
\CommentTok{# treatment).}
\NormalTok{pvalues =}\StringTok{ }\KeywordTok{DE_timecourse}\NormalTok{(}
\NormalTok{    data, splines_model, contrasts,}
    \DataTypeTok{use_voom_weights=}\OtherTok{FALSE}\NormalTok{)}
\NormalTok{qvalues =}\StringTok{ }\KeywordTok{apply}\NormalTok{(pvalues, }\DecValTok{2}\NormalTok{, p.adjust)}
\end{Highlighting}
\end{Shaded}

The number of genes found differentially expressed ranges from around 12000 to
29000 depending on the strain and dosage of influenza virus given to the mice.
This corresponds to between 30\% to 70\% of the genes found differentially
expressed in this time-course experiment.

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/unnamed-chunk-13-1} \end{center}

The next step in a classical differential expression analysis is typically to
assess the effect of the treatment by looking at the log fold change.
Computing the log fold change on a time-course experiment is not trivial: one
can be interested in the average log-fold change across time, or the
cumulative log-fold change. Sometimes a gene can be over-expressed at the
beginning of the time-course data, and then over-expressed at the end of the
experiment. As a result, \texttt{moanin} provides a number of possible ways to
compute the log fold change across the whole time-course.

First, \texttt{moanin} provides as simple interface to compute the log-fold change
for each individual timepoints.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{log_fold_change_timepoints =}\StringTok{ }\KeywordTok{estimate_log_fold_change}\NormalTok{(}
\NormalTok{    data, splines_model, contrasts,  }\DataTypeTok{method=}\StringTok{"timely"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r|r}
\hline
  & M-K:1 & M-K:7 & M-K:11 & M-K:14 & M-K:2\\
\hline
NM\_009912 & -0.0061424 & 0.0224948 & -0.0515947 & -0.1143973 & 0.0614619\\
\hline
NM\_008725 & 2.6547855 & 0.2734387 & -0.6882925 & 0.4718807 & -1.7463319\\
\hline
NM\_007473 & -0.1603623 & 0.1017655 & 0.5079573 & 0.0595773 & 0.4250185\\
\hline
ENSMUST00000094955 & 0.3505920 & 0.6463011 & 0.2564796 & 0.3599102 & 0.4177116\\
\hline
NM\_001042489 & 0.0889750 & 0.2321381 & -0.1891501 & 0.1786113 & 0.3320644\\
\hline
NM\_008159 & -0.3863770 & 0.0298395 & -0.0862755 & -0.3266351 & -0.1893062\\
\hline
\end{tabular}

This matrix can then be used to visualize the log-fold change for each
contrast per timepoint.

Sometimes, a single value per gene and per contrast is more useful. Here is a
table of the possible ways to compute log-fold change values.

\begin{longtable}[]{@{}lll@{}}
\toprule
Name & Formula &\tabularnewline
\midrule
\endhead
timely & \(\text{lfc}(t)\) & Function of time\tabularnewline
sum & \(\sum_t lfc(t)\) & Sum of log fold change.\tabularnewline
abs\_sum & \(\sum_t \|lfc(t)\|\) & Always positive\tabularnewline
max & \(\max_t \|lfc(t)\|\) & Always positive\tabularnewline
min & \(\min_t \|lfc(t)\|\) & Always positive\tabularnewline
epicon & \$\$ & Captures overall strength of response and overall direction\tabularnewline
\bottomrule
\end{longtable}

\textbf{EAP: \texttt{epicon} is going to be weird for general use}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{log_fold_change_epicon =}\StringTok{ }\KeywordTok{estimate_log_fold_change}\NormalTok{(}
\NormalTok{    data, splines_model, contrasts,  }\DataTypeTok{method=}\StringTok{"epicon"}\NormalTok{)}

\NormalTok{log_fold_change_sum =}\StringTok{ }\KeywordTok{estimate_log_fold_change}\NormalTok{(}
\NormalTok{    data, splines_model, contrasts,  }\DataTypeTok{method=}\StringTok{"sum"}\NormalTok{)}

\NormalTok{log_fold_change_max =}\StringTok{ }\KeywordTok{estimate_log_fold_change}\NormalTok{(}
\NormalTok{    data, splines_model, contrasts, }\DataTypeTok{method=}\StringTok{"max"}\NormalTok{)}

\NormalTok{log_fold_change_min =}\StringTok{ }\KeywordTok{estimate_log_fold_change}\NormalTok{(}
\NormalTok{    data, splines_model, contrasts, }\DataTypeTok{method=}\StringTok{"min"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/unnamed-chunk-17-1} \end{center}

From the single measures of log-fold change and the p-value, we can now look
at the volcano plot. Here is an example of a volcano plot for the comparaison
of the control to the Kawasaki strain, using the EPICON log fold change
computation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pvalue =}\StringTok{ }\NormalTok{qvalues[, }\StringTok{"M-K"}\NormalTok{]}
\NormalTok{lfc_epicon =}\StringTok{ }\NormalTok{log_fold_change_epicon[, }\StringTok{"M-K"}\NormalTok{]}
\KeywordTok{names}\NormalTok{(lfc_epicon) =}\StringTok{ }\KeywordTok{row.names}\NormalTok{(log_fold_change_epicon)}

\KeywordTok{plot}\NormalTok{(lfc_epicon, }\OperatorTok{-}\KeywordTok{log10}\NormalTok{(pvalue), }\DataTypeTok{pch=}\DecValTok{20}\NormalTok{, }\DataTypeTok{main=}\StringTok{"Volcano plot"}\NormalTok{,}
     \DataTypeTok{xlim=}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\FloatTok{2.5}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/unnamed-chunk-18-1} \end{center}

As another sanity check, \texttt{moanin} provides a simple utility function to
visualize gene time-course data. Here, we plot the 12 genes with the smallest
p-values.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top_DE_genes_pval =}\StringTok{ }\KeywordTok{names}\NormalTok{(}\KeywordTok{sort}\NormalTok{(pvalue)[}\DecValTok{1}\OperatorTok{:}\DecValTok{12}\NormalTok{])}
\KeywordTok{plot_genes}\NormalTok{(data[top_DE_genes_pval, ], splines_model,}
           \DataTypeTok{colors=}\NormalTok{ann_colors}\OperatorTok{$}\NormalTok{Group, }\DataTypeTok{smooth=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/unnamed-chunk-19-1} \end{center}

And here we visualize the genes with the largest absolute EPICON log-fold
change.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top_DE_genes_lfc =}\StringTok{ }\KeywordTok{names}\NormalTok{(}
    \KeywordTok{sort}\NormalTok{(}\KeywordTok{abs}\NormalTok{(lfc_epicon),}
     \DataTypeTok{decreasing=}\OtherTok{TRUE}\NormalTok{)[}\DecValTok{1}\OperatorTok{:}\DecValTok{12}\NormalTok{])}
\KeywordTok{plot_genes}\NormalTok{(data[top_DE_genes_lfc, ], splines_model,}
           \DataTypeTok{colors=}\NormalTok{ann_colors}\OperatorTok{$}\NormalTok{Group, }\DataTypeTok{smooth=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/unnamed-chunk-20-1} \end{center}

Thanks to those visualization, we can see that genes often follow similar
patterns of expression, although on a different scale for each gene. We can
leverage this observation to cluster the genes into groups of similar patterns
of transcriptomic response.

\hypertarget{clustering-of-time-course-data}{%
\subsection{Clustering of time-course data}\label{clustering-of-time-course-data}}

The very large number of genes found differentially expressed impair any
interpretation one would attempt: with 70\% of the genome found differentially
expressed, all pathways are affected by the treatment. Hence the next step of
the workflow to cluster gene expression according to their dynamical response
to the treatment. Before clustering the genes, we first reduce the set of
genes of interest to genes that are (1) significantly found differentially
expressed; (2) ``highly'' differentially expressed. To do this, we first
aggregate all p-values obtained during the time-course differential expresison
step in a single p-value using Fisher's method \citep{fisher:statistical}. Then we
select all the genes which have a Fisher adjusted p-value below 0.05 and a log
fold change of at least two between at least one condition and one time-point.
Reducing the set of genes on which to perform the clustering allows to
estimate the centroids with more stability.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Then rank by fisher's p-value and take max the number of genes of interest}
\CommentTok{# Filter out q-values for the pvalues table}
\NormalTok{fishers_pval =}\StringTok{ }\KeywordTok{pvalues_fisher_method}\NormalTok{(pvalues)}
\NormalTok{fishers_qval =}\StringTok{ }\KeywordTok{p.adjust}\NormalTok{(fishers_pval)}

\NormalTok{genes_to_keep =}\StringTok{ }\KeywordTok{row.names}\NormalTok{(}
\NormalTok{    log_fold_change_max[}
\NormalTok{    (}\KeywordTok{rowSums}\NormalTok{(log_fold_change_max }\OperatorTok{>}\StringTok{ }\DecValTok{2}\NormalTok{) }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{) }\OperatorTok{&}
\StringTok{    }\NormalTok{(fishers_qval }\OperatorTok{<}\StringTok{ }\FloatTok{0.05}\NormalTok{), ])}
\CommentTok{# Keep the data corresponding to the genes of interest in another variable.}
\NormalTok{y =}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(data[genes_to_keep, ])}
\end{Highlighting}
\end{Shaded}

After filtering, we are left with 3950 genes. We can then apply a
clustering. As observed by looking at genes found differentially expressed,
many genes share a similar gene expression pattern, but on different scale.
We thus propose the following adaptation of k-means:

\begin{itemize}
\tightlist
\item
  \textbf{Splines estimation}: for each gene, fit the splines function with the basis
  of your choice.
\item
  \textbf{Rescaling splines}: for each gene, rescale the estimated splines function
  such that the values are bounded between 0 and 1.
\item
  \textbf{K-means}: apply k-means on the rescaled fitted splines to estimate the
  centroids.
\item
  \textbf{Assign scores and labels to all genes}: then assign a score and a label
  to all gene based on a goodness-of-fit measure on the raw data. By default,
  the \texttt{splines\_kmeans\_score\_and\_label} function only labels the best 50\% of
  genes.
\end{itemize}

The first three steps are performed jointly by the \texttt{splines\_kmeans} function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# First fit the kmeans clusters}
\NormalTok{kmeans_clusters =}\StringTok{ }\KeywordTok{splines_kmeans}\NormalTok{(}
\NormalTok{    y, splines_model, }\DataTypeTok{n_clusters=}\DecValTok{8}\NormalTok{,}
    \DataTypeTok{random_seed=}\DecValTok{42}\NormalTok{,}
    \DataTypeTok{n_init=}\DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We then use the \texttt{plot\_centroids} function to visualize the centroids obtained
with the splines k-means model.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_centroids}\NormalTok{(kmeans_clusters}\OperatorTok{$}\NormalTok{centroids, splines_model,}
               \DataTypeTok{colors=}\NormalTok{ann_colors}\OperatorTok{$}\NormalTok{Group,}
               \DataTypeTok{smooth=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/unnamed-chunk-21-1} \end{center}

The scoring and labeling can be done via the \texttt{splines\_kmeans\_score\_and\_label}
function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#<c2><a0>Then assign scores and labels to all the data, using a goodness-of-fit}
\CommentTok{# scoring function.}
\NormalTok{scores_and_labels =}\StringTok{ }\KeywordTok{splines_kmeans_score_and_label}\NormalTok{(}
\NormalTok{    data, kmeans_clusters)}
\NormalTok{labels =}\StringTok{ }\NormalTok{scores_and_labels}\OperatorTok{$}\NormalTok{labels}

\CommentTok{# Let's keep only the list of genes that have a label.}
\NormalTok{labels =}\StringTok{ }\KeywordTok{unlist}\NormalTok{(labels[}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(labels)])}
\end{Highlighting}
\end{Shaded}

Before performing the next steps, let us investigate in more detail the
differences between the labels provided by the splines k-means model and the
scoring and labelinig step.

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/unnamed-chunk-23-1} \end{center}

The scoring and label step allows to label genes that were removed during the
filtering step, yet are good matches to the centroids found during the
clustering.

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/unnamed-chunk-24-1} \end{center}

\hypertarget{looking-at-specific-clusters-in-details.}{%
\subsubsection{Looking at specific clusters in details.}\label{looking-at-specific-clusters-in-details.}}

Now, let us look more in detail some specific clusters. Cluster 8 seems
particularly interesting: it captures genes with strong differences between
the differant influenza treatments and the control, while the control remains
relatively flat.

Heatmaps are useful to investigate the range of expression patterns for
specific genes. Here, we are going to plot heatmaps of the normalized gene
expression patterns and the rescaled gene expression patterns side by side.

First, select the genes of interest.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster_to_plot =}\StringTok{ }\DecValTok{8}
\NormalTok{genes_to_plot =}\StringTok{  }\KeywordTok{names}\NormalTok{(labels[labels }\OperatorTok{==}\StringTok{ }\NormalTok{cluster_to_plot])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{layout}\NormalTok{(}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{),}\DataTypeTok{nrow=}\DecValTok{1}\NormalTok{), }\DataTypeTok{widths=}\KeywordTok{c}\NormalTok{(}\FloatTok{1.5}\NormalTok{, }\DecValTok{2}\NormalTok{))}

\NormalTok{data_to_plot =}\StringTok{ }\NormalTok{data[genes_to_plot, ]}
\NormalTok{submeta =}\StringTok{ }\NormalTok{meta}
\NormalTok{ord =}\StringTok{ }\KeywordTok{order}\NormalTok{(}
\NormalTok{  submeta}\OperatorTok{$}\NormalTok{Group,}
\NormalTok{  submeta}\OperatorTok{$}\NormalTok{Timepoint,}
\NormalTok{  submeta}\OperatorTok{$}\NormalTok{Replicate)}
\NormalTok{submeta}\OperatorTok{$}\NormalTok{Timepoint =}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(submeta}\OperatorTok{$}\NormalTok{Timepoint)}

\NormalTok{data_to_plot =}\StringTok{ }\NormalTok{data_to_plot[, ord]}
\NormalTok{submeta =}\StringTok{ }\NormalTok{submeta[ord, ]}

\NormalTok{res =}\StringTok{ }\KeywordTok{aheatmap}\NormalTok{(}
\NormalTok{    data_to_plot,}
    \DataTypeTok{Colv=}\OtherTok{NA}\NormalTok{,}
    \DataTypeTok{color=}\StringTok{"YlGnBu"}\NormalTok{,}
    \DataTypeTok{annCol=}\NormalTok{submeta[,}
                \KeywordTok{c}\NormalTok{(}\StringTok{"Group"}\NormalTok{, }\StringTok{"Timepoint"}\NormalTok{)],}
    \DataTypeTok{annLegend=}\OtherTok{FALSE}\NormalTok{,}
    \DataTypeTok{annColors=}\NormalTok{ann_colors,}
    \DataTypeTok{main=}\KeywordTok{paste}\NormalTok{(}\StringTok{"Cluster"}\NormalTok{, cluster_to_plot, }\StringTok{"(raw)"}\NormalTok{),}
    \DataTypeTok{treeheight=}\DecValTok{0}\NormalTok{, }\DataTypeTok{legend=}\OtherTok{FALSE}\NormalTok{)}

\CommentTok{# Now use the results of the previous call to aheatmap to reorder the genes.}
\KeywordTok{aheatmap}\NormalTok{(}
\NormalTok{    moanin}\OperatorTok{:::}\KeywordTok{rescale_values}\NormalTok{(data_to_plot)[res}\OperatorTok{$}\NormalTok{rowInd,],}
    \DataTypeTok{Colv=}\OtherTok{NA}\NormalTok{,}
    \DataTypeTok{Rowv=}\OtherTok{NA}\NormalTok{,}
    \DataTypeTok{annCol=}\NormalTok{submeta[,}
                \KeywordTok{c}\NormalTok{(}\StringTok{"Group"}\NormalTok{, }\StringTok{"Timepoint"}\NormalTok{)],}
    \DataTypeTok{annLegend=}\OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{annColors=}\NormalTok{ann_colors,}
    \DataTypeTok{main=}\KeywordTok{paste}\NormalTok{(}\StringTok{"Cluster"}\NormalTok{, cluster_to_plot, }\StringTok{"(rescaled)"}\NormalTok{),}
    \DataTypeTok{treeheight=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/unnamed-chunk-27-1} \end{center}

Those two heatmaps demonstrate that the clustering method successfully cluster
genes that are on different scales, and yet share the same dynamical response
to the treatments.

\hypertarget{how-to-choose-the-number-of-clusters.}{%
\subsubsection{How to choose the number of clusters.}\label{how-to-choose-the-number-of-clusters.}}

A common question that arises when performing clustering is how to choose the
number of clusters. A choice for the number of clusters K depends on the goal.
In this particular case, the end goal is not the clustering, but to facilitate
interpretation of the differential expression analysis step. As a result, the
number of clusters should not exceed the number of gene sets the user wants to
interpret. This allows to set a maximum number of clusters. Let us assume here
that this number is 20 clusters.

Once the maximum number of clusters is set, several strategies allow to
identify the number of clusters:

\begin{itemize}
\tightlist
\item
  \textbf{Elbow method}. First introduced in 1953 by Thorndike \citep{thorndike:who},
  the elbow methods looks at the total with cluster sum of squares
  as a function of the number of clusters (WCSS). When adding clusters
  doesn't decrease the WCSS by a sufficient
  amount, one can consider stopping. This method thus provides visual aid to
  the user to choose the number of clusters, but often the ``elbow'' is hard to
  see on real data, where the number of clusters is not clearly defined.
\item
  \textbf{Silhouette method}. Similarly to the Elbow method, the Silhouette method
  refers to a method of validation of consistency within clusters, and
  provides visual aid to choose the number of clusters.
\item
  \textbf{Stability methods} Stability methods are more computationally intensive
  than any other method, as they rely on assessing the stability of the
  clustering for every \(k\) to a small randomization of the data. The user is
  then invited to choose the number of cluster based on a number of similarity
  measures.
\end{itemize}

First, let us run the clustering for all possible clusters of interest. We
will, for each clustering experiment, conserve (1) with within cluster sum of
squares; (2) the labels assigned to all genes.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all_possible_n_clusters =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{15}\NormalTok{)}
\NormalTok{all_clustering =}\StringTok{ }\KeywordTok{list}\NormalTok{()}
\NormalTok{wss_values =}\StringTok{ }\KeywordTok{list}\NormalTok{()}

\NormalTok{i =}\StringTok{ }\DecValTok{1}
\ControlFlowTok{for}\NormalTok{(n_cluster }\ControlFlowTok{in}\NormalTok{ all_possible_n_clusters)\{}
\NormalTok{    clustering_results =}\StringTok{ }\KeywordTok{splines_kmeans}\NormalTok{(}
\NormalTok{    y, splines_model,}
    \DataTypeTok{n_clusters=}\NormalTok{n_cluster, }\DataTypeTok{random_seed=}\DecValTok{42}\NormalTok{,}
    \DataTypeTok{n_init=}\DecValTok{10}\NormalTok{)}
\NormalTok{    wss_values[i] =}\StringTok{ }\KeywordTok{sum}\NormalTok{(clustering_results}\OperatorTok{$}\NormalTok{WCSS_per_cluster)}
\NormalTok{    all_clustering[[i]] =}\StringTok{ }\NormalTok{clustering_results}\OperatorTok{$}\NormalTok{clusters}
\NormalTok{    i =}\StringTok{ }\NormalTok{i }\OperatorTok{+}\StringTok{ }\DecValTok{1}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{elbow-method}{%
\paragraph{Elbow method}\label{elbow-method}}

The Elbow method to choose the number of clusters relies on visualization aid
to choose the number of cluster. The method relies on plotting the within
cluster sum of squares as a function of the number of clusters. At some point,
the WCSS will stop dropping, giving an angle in the graph. The number of
cluster is chosen at this ``Elbow point.''

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(all_possible_n_clusters, wss_values,}
     \DataTypeTok{type=}\StringTok{"b"}\NormalTok{, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{frame=}\OtherTok{FALSE}\NormalTok{, }
     \DataTypeTok{xlab=}\StringTok{"Number of clusters K"}\NormalTok{,}
     \DataTypeTok{ylab=}\StringTok{"Total within-clusters sum of squares"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/elbow_method-1} \end{center}

\hypertarget{average-silhouette-method}{%
\paragraph{Average silhouette method}\label{average-silhouette-method}}

The silhouette value is a measure of how similar a data point is to its own
cluster (cohesion) compared to other clusters (separation).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# function to compute average silhouette for k clusters}
\NormalTok{average_silhouette =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(labels, y) \{}
\NormalTok{    silhouette_results =}\StringTok{ }\KeywordTok{silhouette}\NormalTok{(}\KeywordTok{unlist}\NormalTok{(labels[}\DecValTok{1}\NormalTok{]), }\KeywordTok{dist}\NormalTok{(y))}
    \KeywordTok{return}\NormalTok{(}\KeywordTok{mean}\NormalTok{(silhouette_results[, }\DecValTok{3}\NormalTok{]))}
\NormalTok{\}}

\CommentTok{# extract the average silhouette}
\NormalTok{average_silhouette_values =}\StringTok{ }\KeywordTok{list}\NormalTok{()}
\NormalTok{i =}\StringTok{ }\DecValTok{1}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(all_clustering))\{}
\NormalTok{    clustering_results =}\StringTok{ }\NormalTok{all_clustering[i]}
\NormalTok{    average_silhouette_values[i] =}\StringTok{ }\KeywordTok{average_silhouette}\NormalTok{(clustering_results, y)}
\NormalTok{    i =}\StringTok{ }\NormalTok{i }\OperatorTok{+}\StringTok{ }\DecValTok{1}
\NormalTok{\}}

\KeywordTok{plot}\NormalTok{(all_possible_n_clusters, average_silhouette_values,}
     \DataTypeTok{type=}\StringTok{"b"}\NormalTok{, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{frame=}\OtherTok{FALSE}\NormalTok{,}
     \DataTypeTok{xlab=}\StringTok{"Number of clusters K"}\NormalTok{,}
     \DataTypeTok{ylab=}\StringTok{"Average Silhouettes"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/average_silhouette_method-1} \end{center}

\hypertarget{looking-at-the-stability-of-the-clustering}{%
\paragraph{Looking at the stability of the clustering}\label{looking-at-the-stability-of-the-clustering}}

On real data, the number of clusters is not only unknown but also
ambiguous: it will depend on the desired clustering resolution of the user.
Yet, in the case of biological data, stability and reproducibility of the
results is necessary to ensure that the biological interpretation of the
results hold when the data or the model is exposed to reasonable
perturbations.

Methods that rely on the stability of the clustering results to choose \(k\)
thus ensure that the biological interpretation of the clusters hold with
perturbtation to the data. In addition, simulation where the data is generated
with a well defined \(k\) show that the clustering is more stable for the
correct of number of the clusters.

Most methods method to find the number of clusters with stability measures
only provide visual aids to guide the user. The first element often visualized
is the consensus matrix: the consensus matrix is an \(n \times n\) matrix that
stores the proportion of clustering in which two items are clustered together.
A perfect consensus matrix ordered such as each elements that belong to the
same cluster are adjacent to one another which show blocks along the diagonal
close to 1.

To perform such analysis, the first step is run the clustering several times
on a resampled dataset--either using bootstrap or subsampling.

Using the bootstrapping strategy:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n_genes =}\StringTok{ }\KeywordTok{dim}\NormalTok{(y)[}\DecValTok{1}\NormalTok{]}
\NormalTok{indices =}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{dim}\NormalTok{(y)[}\DecValTok{1}\NormalTok{], n_genes, }\DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{)}

\NormalTok{bootstrapped_y =}\StringTok{ }\NormalTok{y[indices, ]}
\end{Highlighting}
\end{Shaded}

Using the subsampling strategy, keeping 80\% of the genes:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subsample_proportion =}\StringTok{ }\DecValTok{1}
\NormalTok{indices =}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{dim}\NormalTok{(y)[}\DecValTok{1}\NormalTok{], n_genes }\OperatorTok{*}\StringTok{ }\NormalTok{subsample_proportion, }\DataTypeTok{replace=}\OtherTok{FALSE}\NormalTok{)}
\NormalTok{subsampled_y =}\StringTok{ }\NormalTok{y[indices, ]}
\end{Highlighting}
\end{Shaded}

Here we plot to stability matrix of the top 1000 genes for \(k=5\) and \(k=20\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stability_}\DecValTok{5}\NormalTok{ =}\StringTok{ }\KeywordTok{read.table}\NormalTok{(}\StringTok{"results/stability_5.tsv"}\NormalTok{, }\DataTypeTok{sep=}\StringTok{"}\CharTok{\textbackslash{}t}\StringTok{"}\NormalTok{)}
\NormalTok{consensus_matrix_stability_}\DecValTok{5}\NormalTok{ =}\StringTok{ }\KeywordTok{consensus_matrix}\NormalTok{(stability_}\DecValTok{5}\NormalTok{,}
                            \DataTypeTok{scale=}\OtherTok{FALSE}\NormalTok{)}
\KeywordTok{aheatmap}\NormalTok{(consensus_matrix_stability_}\DecValTok{5}\NormalTok{[}\DecValTok{1}\OperatorTok{:}\DecValTok{1000}\NormalTok{, }\DecValTok{1}\OperatorTok{:}\DecValTok{1000}\NormalTok{], }\DataTypeTok{Rowv=}\OtherTok{FALSE}\NormalTok{,}
     \DataTypeTok{Colv=}\OtherTok{FALSE}\NormalTok{,}
     \DataTypeTok{treeheight=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/unnamed-chunk-30-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stability_}\DecValTok{20}\NormalTok{ =}\StringTok{ }\KeywordTok{read.table}\NormalTok{(}\StringTok{"results/stability_20.tsv"}\NormalTok{, }\DataTypeTok{sep=}\StringTok{"}\CharTok{\textbackslash{}t}\StringTok{"}\NormalTok{)}
\NormalTok{consensus_matrix_stability_}\DecValTok{20}\NormalTok{ =}\StringTok{ }\KeywordTok{consensus_matrix}\NormalTok{(stability_}\DecValTok{20}\NormalTok{,}
                         \DataTypeTok{scale=}\OtherTok{FALSE}\NormalTok{)}
\KeywordTok{aheatmap}\NormalTok{(consensus_matrix_stability_}\DecValTok{20}\NormalTok{[}\DecValTok{1}\OperatorTok{:}\DecValTok{1000}\NormalTok{, }\DecValTok{1}\OperatorTok{:}\DecValTok{1000}\NormalTok{], }\DataTypeTok{Rowv=}\OtherTok{FALSE}\NormalTok{,}
     \DataTypeTok{Colv=}\OtherTok{FALSE}\NormalTok{,}
     \DataTypeTok{treeheight=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/unnamed-chunk-30-2} \end{center}

\hypertarget{the-model-explorer-strategy}{%
\subparagraph{The model explorer strategy}\label{the-model-explorer-strategy}}

The model explorer algorithm \citep{ben-hur:stability} proposes to estimate the
number of clusters exploiting the observation that if the number of clusters
is correct, the clustering results are stable to bootstrapping. The
distribution of similaries between bootstrapped results for each \(k\) can thus
be compared for different values of \(k\) and guide the user in the choice of
number of clusters.

The model explorer strategy works as follows. First, choose a similarity
measure between two partitions or clusters \(S(C_1, C_2)\). Examples are the
normalized mutual information or Fowlkes-Mallows. Then perform \(n\) bootstrap
experiments to estimate the cluster centroids, followed by a step of assigning
a label to all data points. Finally, compute the pairwise similarity measure
between all bootstrapped partition, and plot the cumulative density of the
obtained scores.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_model_explorer}\NormalTok{(all_labels)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/unnamed-chunk-32-1} \end{center}

From this plot, we can deduce that \(k=5\) is more stable than \(k=3\) and \(k=4\),
but not as stable as \(k=2\). The model explorer strategy, in addition to
visualizing the diversity of the centroids, can thus help assessing an
adequate number of clusters.

Now, replot the same model explorer, but only for the clustering experiments
\(k=6\), \(k=7\), \(k=8\), \(k=9\) and \(k=10\) so that we can see more clearly the stability
measures in that range.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clusters =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"C6"}\NormalTok{, }\StringTok{"C7"}\NormalTok{, }\StringTok{"C8"}\NormalTok{, }\StringTok{"C9"}\NormalTok{, }\StringTok{"C10"}\NormalTok{)}
\NormalTok{selected_labels =}\StringTok{ }\NormalTok{all_labels[clusters]}
\KeywordTok{plot_model_explorer}\NormalTok{(selected_labels)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{reports/manuscript_files/figure-latex/unnamed-chunk-33-1} \end{center}

\hypertarget{consensus-clustering-as-a-way-to-find-k}{%
\subparagraph{\texorpdfstring{Consensus clustering as a way to find \(k\)}{Consensus clustering as a way to find k}}\label{consensus-clustering-as-a-way-to-find-k}}

The consensus clustering \citep{monti:consensus} relies on a similar idea but
instead of looking at the cumulative density of similarity measures of
bootstrapped clustering, the authors suggests plotting the cumulative density
of elements of the consensus matrix.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot_cdf_consensus}\NormalTok{(all_labels)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=6.67in]{images/clustering_CDF_consensus} \end{center}

The stability of the clustering based on the consensus matrix can then be
measured via a single number by looking at the area under the curve: the more
stable the clustering, the closer to 0 or 1 will be the entries of consensus
matrix. The consensus clustering strategy thus suggest at looking at either
the AUC as a function of the number of the clusters or the ``improvement'' in
the AUC as a function of the number of cluster.

\begin{center}\includegraphics[width=6.67in]{images/clustering_AUC_consensus} \end{center}

\begin{center}\includegraphics[width=6.67in]{images/clustering_delta_AUC_consensus} \end{center}

The consensus clustering method suggest that the most stable is \(k=2\), which
separates over-expressed genes from under-expressed genes. While it is indeed
a very stable clustering, it does not capture the range of gene expression
patterns present in the data. This shows the limitation of such method on real
data, where the number of clusters is not clearly defined.

\hypertarget{downstream-analysis-of-clusters.}{%
\subsection{Downstream analysis of clusters.}\label{downstream-analysis-of-clusters.}}

Once good clusters are obtained, the next step is to leverage the clustering
to ease interpretation. Classic enrichment analysis step can then be performed
in the gene set defined in each cluster: KEGG pathway enrichment analysis, GO
term enrichment analysis, motif enrichment analysis, etc.

First, let us clean up the gene obtained and only select the genes we are
going to use in the enrichment analysis. One can either use the whole set of
genes, only the set of differentially expressed genes in each cluster, or a
subset of genes that fit well to a cluster (based on some criterion).

\hypertarget{finding-enriched-pathways-using-biomart-and-keggprofile}{%
\subsubsection{\texorpdfstring{Finding enriched pathways using \texttt{biomaRt} and \texttt{KEGGprofile}}{Finding enriched pathways using biomaRt and KEGGprofile}}\label{finding-enriched-pathways-using-biomart-and-keggprofile}}

Let us first tackle the case of pathway enrichment analysis. We will leverage
the packages \texttt{biomaRt} \citep{durinck:biomart} and \texttt{KEGGprofile} \citep{zhao:keggprofile}
for this step. \texttt{KEGGprofile} is a
package that easily allows to perform pathway enrichment analysis on a set of
genes labeled with the ensembl annotation. We thus need to convert the gene
names into the appropriate format. This is where \texttt{biomaRt} comes in handy: it
enables easy conversion from one gene annotation to another. Here, we will use
it to convert the gene names from the Refseq annotation to the ensembl one.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ensembl =}\StringTok{ }\KeywordTok{useMart}\NormalTok{(}\StringTok{"ensembl"}\NormalTok{)}
\NormalTok{ensembl =}\StringTok{ }\KeywordTok{useDataset}\NormalTok{(}\StringTok{"mmusculus_gene_ensembl"}\NormalTok{, }\DataTypeTok{mart=}\NormalTok{ensembl)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster =}\StringTok{ }\DecValTok{8}
\NormalTok{labels =}\StringTok{ }\KeywordTok{unlist}\NormalTok{(labels)}
\NormalTok{gene_names =}\StringTok{ }\KeywordTok{names}\NormalTok{(labels)}
\NormalTok{genes =}\StringTok{ }\NormalTok{gene_names[labels }\OperatorTok{==}\StringTok{ }\NormalTok{cluster]}

\CommentTok{# convert gene names}
\NormalTok{genes =}\StringTok{ }\KeywordTok{getBM}\NormalTok{(}\DataTypeTok{attributes=}\KeywordTok{c}\NormalTok{(}\StringTok{"ensembl_gene_id"}\NormalTok{, }\StringTok{"entrezgene_id"}\NormalTok{),}
        \DataTypeTok{filters=}\StringTok{"refseq_mrna"}\NormalTok{, }\DataTypeTok{values=}\NormalTok{genes,}
        \DataTypeTok{mart=}\NormalTok{ensembl)[}\StringTok{"entrezgene_id"}\NormalTok{]}
\NormalTok{genes =}\StringTok{ }\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{unlist}\NormalTok{(genes))}
\NormalTok{pathways =}\StringTok{ }\KeywordTok{find_enriched_pathway}\NormalTok{(}
\NormalTok{    genes, }\DataTypeTok{species=}\StringTok{"mmu"}\NormalTok{,}
    \DataTypeTok{download_latest=}\OtherTok{TRUE}\NormalTok{)}\OperatorTok{$}\NormalTok{stastic}
\end{Highlighting}
\end{Shaded}

\begin{tabu} to \linewidth {>{\raggedright}X>{\raggedright}X>{\raggedleft}X>{\raggedleft}X}
\hline
  & Pathway & Percentage & Adj. p-value\\
\hline
05169 & Epstein-Barr virus infection & 37 & 0\\
\hline
04060 & Cytokine-cytokine receptor interaction & 31 & 0\\
\hline
04668 & TNF signaling pathway & 45 & 0\\
\hline
05164 & Influenza A & 38 & 0\\
\hline
04621 & NOD-like receptor signaling pathway & 34 & 0\\
\hline
05162 & Measles & 37 & 0\\
\hline
04630 & JAK-STAT signaling pathway & 33 & 0\\
\hline
05160 & Hepatitis C & 34 & 0\\
\hline
04620 & Toll-like receptor signaling pathway & 40 & 0\\
\hline
05167 & Kaposi sarcoma-associated herpesvirus infection & 29 & 0\\
\hline
\end{tabu}

\hypertarget{finding-enriched-go-terms}{%
\subsubsection{Finding enriched GO terms}\label{finding-enriched-go-terms}}

To find GO terms, we use \texttt{biomaRt} to find the mapping between GO terms and
gene mapping. The GO enrichment library \texttt{topGO} \citep{alexa:topgo} expects the GO term to gene
mapping to be a list where each item is a mapping between a gene name and a GO
term ID vector.

\begin{verbatim}
$NM_199153
[1] "GO:0016020" "GO:0016021" "GO:0007186" "GO:0004930" "GO:0007165"
[6] "GO:0050896" "GO:0050909"

$NM_201361
 [1] "GO:0016020" "GO:0016021" "GO:0003674" "GO:0008150" "GO:0005794"
 [6] "GO:0005829" "GO:0005737" "GO:0005856" "GO:0005874" "GO:0005739"
[11] "GO:0005819" "GO:0000922" "GO:0072686"
\end{verbatim}

\texttt{biomaRt} queries results a matrix with two named columns of gene names and GO
term ID.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{genes =}\StringTok{ }\KeywordTok{getBM}\NormalTok{(}\DataTypeTok{attributes=}\KeywordTok{c}\NormalTok{(}\StringTok{"go_id"}\NormalTok{, }\StringTok{"refseq_mrna"}\NormalTok{),}
          \DataTypeTok{values=}\NormalTok{gene_names,}
          \DataTypeTok{filters=}\StringTok{"refseq_mrna"}\NormalTok{,}
          \DataTypeTok{mart=}\NormalTok{ensembl)}

\CommentTok{# Create gene to GO id mapping}
\NormalTok{gene_id_go_mapping =}\StringTok{ }\KeywordTok{create_go_term_mapping}\NormalTok{(genes)}
\end{Highlighting}
\end{Shaded}

Once the gene ID to GO mapping list is created, \texttt{moanin} provides a simple
interface to \texttt{topGO} to fetch enriched GO terms. Here, we show an example of
running a GOterm enrichment on the ``Biological process'' ontology (BP).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{assignments =}\StringTok{ }\NormalTok{labels }\OperatorTok{==}\StringTok{ }\NormalTok{cluster}

\NormalTok{go_terms_enriched =}\StringTok{ }\KeywordTok{find_enriched_go_terms}\NormalTok{(}
\NormalTok{    assignments,}
\NormalTok{    gene_id_go_mapping, }\DataTypeTok{ontology=}\StringTok{"BP"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabu} to \linewidth {>{\raggedright}X>{\raggedright}X>{\raggedright}X>{\raggedleft}X>{\raggedleft}X>{\raggedleft}X>{\raggedright}X>{\raggedleft}X}
\hline
  & GO ID & Description & Annotated & Significant & Expected & P-value & adj. p-value\\
\hline
5 & GO:0003002 & regionalization & 172 & 153 & 134.41 & 0.00026 & 0.2629\\
\hline
6 & GO:0048562 & embryonic organ morphogenesis & 152 & 135 & 118.78 & 0.00045 & 0.3323\\
\hline
7 & GO:0010970 & transport along microtubule & 82 & 75 & 64.08 & 0.00046 & 0.3323\\
\hline
8 & GO:0006805 & xenobiotic metabolic process & 49 & 47 & 38.29 & 0.00059 & 0.3729\\
\hline
9 & GO:0060173 & limb development & 92 & 84 & 71.89 & 0.00068 & 0.3820\\
\hline
10 & GO:0019395 & fatty acid oxidation & 53 & 51 & 41.42 & 0.00134 & 0.6194\\
\hline
11 & GO:0055114 & oxidation-reduction process & 536 & 461 & 418.84 & 0.00139 & 0.6194\\
\hline
12 & GO:0060070 & canonical Wnt signaling pathway & 149 & 131 & 116.43 & 0.00147 & 0.6194\\
\hline
13 & GO:0090596 & sensory organ morphogenesis & 134 & 118 & 104.71 & 0.00219 & 0.8517\\
\hline
14 & GO:0060411 & cardiac septum morphogenesis & 33 & 32 & 25.79 & 0.00295 & 1.0000\\
\hline
15 & GO:0010811 & positive regulation of cell-substrate ad... & 81 & 73 & 63.30 & 0.00384 & 1.0000\\
\hline
16 & GO:0042738 & exogenous drug catabolic process & 22 & 22 & 17.19 & 0.00437 & 1.0000\\
\hline
17 & GO:1901381 & positive regulation of potassium ion tra... & 22 & 22 & 17.19 & 0.00437 & 1.0000\\
\hline
18 & GO:0007368 & determination of left/right symmetry & 66 & 60 & 51.57 & 0.00536 & 1.0000\\
\hline
19 & GO:0060078 & regulation of postsynaptic membrane pote... & 66 & 60 & 51.57 & 0.00536 & 1.0000\\
\hline
\end{tabu}

\hypertarget{session-information}{%
\section{Session information}\label{session-information}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sessionInfo}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## R version 3.6.0 (2019-04-26)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: Ubuntu 19.04
## 
## Matrix products: default
## BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0
## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0
## 
## locale:
## [1] C
## 
## attached base packages:
##  [1] stats4    parallel  splines   stats     graphics  grDevices utils    
##  [8] datasets  methods   base     
## 
## other attached packages:
##  [1] RColorBrewer_1.1-2   moanin_0.0.0         topGO_2.32.0        
##  [4] SparseM_1.77         GO.db_3.6.0          AnnotationDbi_1.42.1
##  [7] IRanges_2.14.12      S4Vectors_0.18.3     graph_1.58.2        
## [10] viridis_0.5.1        viridisLite_0.3.0    KEGGprofile_1.22.0  
## [13] RCurl_1.95-4.12      bitops_1.0-6         NMF_0.21.0          
## [16] Biobase_2.40.0       BiocGenerics_0.26.0  cluster_2.0.9       
## [19] rngtools_1.3.1.1     pkgmaker_0.27        registry_0.5-1      
## [22] ggplot2_3.1.1        biomaRt_2.36.1       BiocStyle_2.8.2     
## [25] kableExtra_1.1.0     knitr_1.22           limma_3.36.5        
## [28] usethis_1.5.0        devtools_2.0.2       rmarkdown_1.12      
## 
## loaded via a namespace (and not attached):
##  [1] colorspace_1.4-1        rprojroot_1.3-2        
##  [3] XVector_0.20.0          fs_1.3.1               
##  [5] rstudioapi_0.10         remotes_2.0.4          
##  [7] bit64_0.9-7             ClusterR_1.1.9         
##  [9] KEGG.db_3.2.3           xml2_1.2.0             
## [11] codetools_0.2-16        doParallel_1.0.14      
## [13] pkgload_1.0.2           ade4_1.7-13            
## [15] gridBase_0.4-7          png_0.1-7              
## [17] FD_1.0-12               readr_1.3.1            
## [19] compiler_3.6.0          httr_1.4.0             
## [21] backports_1.1.4         Matrix_1.2-17          
## [23] assertthat_0.2.1        lazyeval_0.2.2         
## [25] cli_1.1.0               htmltools_0.3.6        
## [27] prettyunits_1.0.2       tools_3.6.0            
## [29] gmp_0.5-13.5            gtable_0.3.0           
## [31] glue_1.3.1              reshape2_1.4.3         
## [33] dplyr_0.8.0.1           BiocWorkflowTools_1.6.2
## [35] Rcpp_1.0.1              Biostrings_2.48.0      
## [37] NMI_2.0                 ape_5.3                
## [39] nlme_3.1-139            iterators_1.0.10       
## [41] xfun_0.6                stringr_1.4.0          
## [43] ps_1.3.0                testthat_2.1.1         
## [45] rvest_0.3.3             gtools_3.8.1           
## [47] XML_3.98-1.19           zlibbioc_1.26.0        
## [49] MASS_7.3-51.4           scales_1.0.0           
## [51] hms_0.4.2               yaml_2.2.0             
## [53] curl_3.3                memoise_1.1.0          
## [55] gridExtra_2.3           TeachingDemos_2.10     
## [57] stringi_1.4.3           RSQLite_2.1.1          
## [59] desc_1.2.0              foreach_1.4.4          
## [61] permute_0.9-5           pkgbuild_1.0.3         
## [63] bibtex_0.4.2            geometry_0.4.1         
## [65] rlang_0.3.4             pkgconfig_2.0.2        
## [67] matrixStats_0.54.0      evaluate_0.13          
## [69] lattice_0.20-38         purrr_0.3.2            
## [71] bit_1.1-14              processx_3.3.1         
## [73] tidyselect_0.2.5        plyr_1.8.4             
## [75] magrittr_1.5            bookdown_0.9           
## [77] R6_2.4.0                DBI_1.0.0              
## [79] mgcv_1.8-28             pillar_1.3.1           
## [81] withr_2.1.2             abind_1.4-5            
## [83] KEGGREST_1.20.2         tibble_2.1.1           
## [85] crayon_1.3.4            progress_1.2.0         
## [87] grid_3.6.0              vegan_2.5-4            
## [89] blob_1.1.1              callr_3.2.0            
## [91] git2r_0.25.2            digest_0.6.18          
## [93] webshot_0.5.1           xtable_1.8-4           
## [95] munsell_0.5.0           magic_1.5-9            
## [97] sessioninfo_1.1.1
\end{verbatim}

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

This workflow provides a tutoral for the analysis of time-course gene
expression data in R, illustrated through the analysis of mice lung tissue
exposed to different influenza strain. It covers four main steps; (1) quality
control and normalization; (2) differential expression analysis; (3)
clustering of time-course gene expression data; (4) downstream analysis of
clusters.

\hypertarget{software-and-data-availability}{%
\section{Software and data availability}\label{software-and-data-availability}}

The source code for this workflow can be found at \url{https://github.com/NelleV/2019timecourse-rnaseq-pipeline}.
Data used in this workflow are available from NCBI GEO, accession GSE95601.

\hypertarget{author-contributions}{%
\section{Author contributions}\label{author-contributions}}

NV and EP wrote the workflow.

\hypertarget{competing-interests}{%
\section{Competing interests}\label{competing-interests}}

The authors declare that they have no competing interests.

\hypertarget{grant-information}{%
\section{Grant information}\label{grant-information}}

This research was funded in part by a Department of Energy (DOE) grant
(DE-SC0014081); by the Gordon and Betty Moore Foundation (Grant GBMF3834) and
the Alfred P. Sloan Foundation (Grant 2013-10-27) to the University of
California, Berkeley {[}N.V.{]}; by a ENS-CFM Data Science Chair {[}E.P.{]}.

\emph{I confirm that the funders had no role in study design, data collection and
analysis, decision to publish, or preparation of the manuscript.}

\hypertarget{acknowledgments}{%
\section{Acknowledgments}\label{acknowledgments}}

The authors thank Karthik Ram and the Ropensci community for valuable
feedback.

\renewcommand\refname{References}
{\small\bibliography{bibliography.bib}}

\end{document}
